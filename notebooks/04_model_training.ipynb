{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1bf21c",
   "metadata": {},
   "source": [
    "## Telco Customer Churn â€“ Modeling\n",
    "\n",
    "### Objective\n",
    "\n",
    "Build, evaluate, and interpret predictive models to identify customers at risk of churn. This notebook focuses on:\n",
    "\n",
    "Robust preprocessing aligned with production use\n",
    "\n",
    "Baseline and advanced models\n",
    "\n",
    "Proper evaluation using business-relevant metrics\n",
    "\n",
    "Model interpretability and actionable insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_recall_curve, auc, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\data\\processed\\featured_telco.csv\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19908f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75917796",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.isna().sum().sum() == 0, \"Data leakage or encoding failure detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7fb5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target sanity check\n",
    "df[\"Churn\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63ad2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"tenure\",\n",
    "    \"MonthlyCharges\",\n",
    "    \"TotalCharges\",\n",
    "    \"avg_monthly_spend\",\n",
    "    \"total_services\"\n",
    "]\n",
    "\n",
    "print(\"Numeric columns to scale:\")\n",
    "print(num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit scaler on train data only\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Save processed test features\n",
    "X_test_scaled.to_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\data\\processed\\X_test.csv\", index=False)\n",
    "\n",
    "# Save test labels\n",
    "y_test.to_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\data\\processed\\y_test.csv\", index=False)\n",
    "\n",
    "# print sanity check\n",
    "\n",
    "print(\"Before scaling (train):\")\n",
    "print(X_train[num_cols].describe().loc[[\"mean\", \"std\"]])\n",
    "\n",
    "print(\"\\nAfter scaling (train):\")\n",
    "print(X_train_scaled[num_cols].describe().loc[[\"mean\", \"std\"]])\n",
    "\n",
    "# save scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9691848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model â€“ Logistic Regression\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_prob_lr = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Default threshold = 0.5\n",
    "y_pred_lr = (y_prob_lr >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "roc_auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression ROC AUC : {roc_auc_lr:.4f}\")\n",
    "print(f\"Precision (Churn=1)         : {precision_lr:.4f}\")\n",
    "print(f\"Recall (Churn=1)            : {recall_lr:.4f}\")\n",
    "\n",
    "# Detailed report\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(log_reg, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\logistic_regression_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba90f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Model â€“ XGBoost (Revenue Optimizer)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob_xgb = xgb.predict_proba(X_test)[:, 1]\n",
    "y_pred_xgb = (y_prob_xgb >= 0.5).astype(int)\n",
    "\n",
    "print(\"XGBoost Metrics:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_xgb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_xgb))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_xgb))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_xgb))\n",
    "\n",
    "# Detailed report\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred_xgb)\n",
    "\n",
    "# Save\n",
    "joblib.dump(xgb, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\xgboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest classifier\n",
    "\n",
    "# Train\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, max_depth=10, random_state=42, class_weight=\"balanced\"\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred_rf = (y_prob_rf >= 0.5).astype(int)\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_rf))\n",
    "\n",
    "# Detailed report   \n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Save the best model\n",
    "import joblib       \n",
    "joblib.dump(rf, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bc3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra trees classifier\n",
    "# Train\n",
    "et = ExtraTreesClassifier(\n",
    "    n_estimators=300, max_depth=10, random_state=42, class_weight=\"balanced\"\n",
    ")\n",
    "et.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob_et = et.predict_proba(X_test)[:, 1]\n",
    "y_pred_et = (y_prob_et >= 0.5).astype(int)\n",
    "\n",
    "print(\"Extra Trees Metrics:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_et))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_et))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_et))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_et))\n",
    "\n",
    "# Detailed report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_et))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred_et)\n",
    "\n",
    "# Save\n",
    "joblib.dump(et, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\extra_trees_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77953a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Classifier\n",
    "\n",
    "# Train\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=300, max_depth=10, learning_rate=0.05, random_state=42\n",
    ")\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob_lgbm = lgbm.predict_proba(X_test)[:, 1]\n",
    "y_pred_lgbm = (y_prob_lgbm >= 0.5).astype(int)\n",
    "\n",
    "print(\"LightGBM Metrics:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_lgbm))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_lgbm))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_lgbm))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_lgbm))\n",
    "\n",
    "# Detailed report\n",
    "print(\"\\nClassification Report:\")               \n",
    "print(classification_report(y_test, y_pred_lgbm))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred_lgbm)\n",
    "\n",
    "# Save\n",
    "joblib.dump(lgbm, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\lightgbm_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84213076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Classifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Train\n",
    "catboost = CatBoostClassifier(\n",
    "    iterations=300, learning_rate=0.05, depth=5, verbose=0, random_state=42\n",
    ")\n",
    "catboost.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_prob_cat = catboost.predict_proba(X_test)[:, 1]\n",
    "y_pred_cat = (y_prob_cat >= 0.5).astype(int)\n",
    "\n",
    "print(\"CatBoost Metrics:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_cat))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_cat))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_cat))\n",
    "print(\"F1:\", f1_score(y_test, y_pred_cat))\n",
    "\n",
    "# Detailed report\n",
    "print(\"\\nClassification Report:\")   \n",
    "print(classification_report(y_test, y_pred_cat))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix(y_test, y_pred_cat)\n",
    "\n",
    "# Save\n",
    "joblib.dump(catboost, r\"C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\\catboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57409029",
   "metadata": {},
   "source": [
    "## Model Training & Persistence\n",
    "\n",
    "### Objective Recap\n",
    "\n",
    "The goal of this notebook was to **train robust churn prediction models** using production-aligned preprocessing and to **persist all inference-critical artifacts** for downstream evaluation and business decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Data Preparation & Scaling\n",
    "\n",
    "* Dataset was split using **stratified trainâ€“test split** to preserve churn distribution.\n",
    "* **StandardScaler** was fitted **only on training data** to prevent data leakage.\n",
    "* Scaling was applied **only to continuous numerical features**:\n",
    "\n",
    "  * `tenure`\n",
    "  * `MonthlyCharges`\n",
    "  * `TotalCharges`\n",
    "  * `avg_monthly_spend`\n",
    "  * `total_services`\n",
    "\n",
    "âœ”ï¸ Categorical and one-hot encoded features were left unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤– Models Trained\n",
    "\n",
    "### Baseline Models\n",
    "\n",
    "* **Logistic Regression**\n",
    "\n",
    "  * Interpretable baseline\n",
    "  * `class_weight=\"balanced\"` to handle churn imbalance\n",
    "* **Decision Tree**\n",
    "\n",
    "  * Rule-based interpretability\n",
    "\n",
    "### Advanced Models\n",
    "\n",
    "* **Random Forest**\n",
    "\n",
    "  * Robust to non-linear feature interactions\n",
    "* **XGBoost**\n",
    "\n",
    "  * Primary candidate for revenue optimization\n",
    "  * Strong performance on structured Telco data\n",
    "\n",
    "> **Note:**\n",
    "> SMOTE was applied **only during training** to address class imbalance and was **intentionally not saved**, as it must never be used during inference.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ˆ Evaluation Strategy\n",
    "\n",
    "* **Primary metric:** Recall for churn class (`Churn = 1`)\n",
    "* **Secondary metric:** ROC-AUC\n",
    "* Predictions were generated using **probability outputs**, enabling future threshold optimization aligned with retention budget constraints.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¾ Persisted Artifacts (Production-Critical)\n",
    "\n",
    "All inference-required artifacts were saved to:\n",
    "\n",
    "```\n",
    "C:\\Users\\admin\\OneDrive\\Desktop\\Telco churn\\models\n",
    "```\n",
    "\n",
    "### Saved Files\n",
    "\n",
    "```\n",
    "models/\n",
    "â”œâ”€â”€ scaler.pkl                     # Fitted StandardScaler\n",
    "â”œâ”€â”€ logistic_regression_model.pkl  # Baseline interpretable model\n",
    "â”œâ”€â”€ random_forest_model.pkl        # Ensemble model\n",
    "â”œâ”€â”€ xgboost_model.pkl              # Final advanced model\n",
    "â”œâ”€â”€models/lightgbm_model.pkl\n",
    "â”œâ”€â”€models/extra_trees_model.pkl\n",
    "â”œâ”€â”€models/catboost_model.pkl\n",
    "```\n",
    "\n",
    "### Persistence Principles\n",
    "\n",
    "* Scaler is **loaded and reused** during evaluation and inference\n",
    "* No training-only artifacts (e.g., SMOTE) are included\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Key Design Decisions\n",
    "\n",
    "* **No data leakage**: scaler fitted on training data only\n",
    "* **Business alignment**: recall prioritized over accuracy\n",
    "* **Production realism**: probabilities retained for threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8d9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
